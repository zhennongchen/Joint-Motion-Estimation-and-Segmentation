{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/Documents')\n",
    "import os\n",
    "import numpy as np \n",
    "import nibabel as nb\n",
    "import pandas as pd\n",
    "import sam_cmr.functions_collection as ff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run following for ACDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/mnt/camca_NAS/SAM_for_CMR/data/ACDC_database/temporal'\n",
    "patient_list_path = '/mnt/camca_NAS/SAM_for_CMR/data/Patient_list/'\n",
    "basic_info_file = pd.read_excel(os.path.join(patient_list_path, 'ACDC_basic_info.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 50 150\n"
     ]
    }
   ],
   "source": [
    "training_dataset = ff.find_all_target_files(['training/*'],os.path.join(data_path))\n",
    "testing_dataset = ff.find_all_target_files(['testing/*'],os.path.join(data_path))\n",
    "all_dataset = ff.find_all_target_files(['training/*','testing/*'],os.path.join(data_path))\n",
    "print(len(training_dataset), len(testing_dataset), len(all_dataset))\n",
    "######### in total there should be 100 training cases and 50 testing cases, 150 cases in total\n",
    "\n",
    "# divide training dataset into 5 batches, batch 0 to batch 4\n",
    "if len(training_dataset)%5 == 0:\n",
    "    batch_size = len(training_dataset)//5\n",
    "else:\n",
    "    batch_size = len(training_dataset)//5 + 1\n",
    "# the testing dataset is an individual batch, batch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(len(all_dataset)):\n",
    "    \n",
    "    folder = all_dataset[i]\n",
    "    patient_id = os.path.basename(folder)\n",
    "    patient_group = os.path.basename(os.path.dirname(folder))\n",
    "\n",
    "    # find the corresponding row in basic info spreadsheet\n",
    "    row = basic_info_file[basic_info_file['patient_id'] == patient_id]\n",
    "    \n",
    "    if patient_group[0:3] == 'tra': # training\n",
    "        batch_index = i // batch_size\n",
    "    else:\n",
    "        \n",
    "      batch_index = 5\n",
    "    \n",
    "    # image file with all slices (including non-zero slices and zero slices)\n",
    "    image_full_slice_file = os.path.join(folder, '4d_temporal_img_full.nii.gz')\n",
    "\n",
    "    # segmentation file with all slices (including non-zero slices and zero slices)\n",
    "    seg_full_slice_file = os.path.join(folder, '4d_temporal_seg_full.nii.gz')\n",
    "\n",
    "    # image file with only nonzero slices - strict: both ED and ES need to have GT segmentation\n",
    "    image_nonzero_slice_file = os.path.join(folder, '4d_temporal_img_nonzero.nii.gz')\n",
    "\n",
    "    # segmentation file with only nonzero slices - strict\n",
    "    seg_nonzero_slice_file = os.path.join(folder, '4d_temporal_seg_nonzero.nii.gz')\n",
    "\n",
    "    # image file with only nonzero slices - loose: only ED or ES need to have GT segmentation\n",
    "    image_nonzero_slice_file_loose = os.path.join(folder, '4d_temporal_img_nonzero_loose.nii.gz')\n",
    "\n",
    "    # segmentation file with only nonzero slices - loose\n",
    "    seg_nonzero_slice_file_loose = os.path.join(folder, '4d_temporal_seg_nonzero_loose.nii.gz')\n",
    "\n",
    "    # image start from 'base' or 'apex'\n",
    "    start_slice_name = row.iloc[0]['start_slice_name']\n",
    "\n",
    "    # image total slice number\n",
    "    total_slice_num = row.iloc[0]['total_slice_num']\n",
    "\n",
    "    # image nonzero slice number\n",
    "    nonzero_slice_num = row.iloc[0]['nonzero_slice_num']\n",
    "\n",
    "    # image nonzero slice start index\n",
    "    nonzero_slice_start_index = row.iloc[0]['nonzero_slice_start_index']\n",
    "\n",
    "    # image nonzero slice end index\n",
    "    nonzero_slice_end_index = row.iloc[0]['nonzero_slice_end_index']\n",
    "\n",
    "    # image nonzero slice number - loose\n",
    "    nonzero_slice_num_loose = row.iloc[0]['nonzero_slice_num_loose']\n",
    "\n",
    "    # image nonzero slice start index - loose\n",
    "    nonzero_slice_start_index_loose = row.iloc[0]['nonzero_slice_start_index_loose']\n",
    "\n",
    "    # image nonzero slice end index - loose\n",
    "    nonzero_slice_end_index_loose = row.iloc[0]['nonzero_slice_end_index_loose']\n",
    "\n",
    "    # original time frame number\n",
    "    original_time_frame_num = row.iloc[0]['tf_num']\n",
    "\n",
    "    # ED time frame\n",
    "    ED = row.iloc[0]['ED']\n",
    "\n",
    "    # ES time frame\n",
    "    ES = row.iloc[0]['ES']\n",
    " \n",
    "    # processed time frame number: always 15, ALWAYS including ED and ES\n",
    "    processed_time_frame_num = row.iloc[0]['processed_time_frame_num']\n",
    "\n",
    "    # ED index in the processed time frame\n",
    "    ED_index_in_processed_time_frame = row.iloc[0]['ED_index_in_processed_time_frame']\n",
    "\n",
    "    # ES index in the processed time frame\n",
    "    ES_index_in_processed_time_frame = row.iloc[0]['ES_index_in_processed_time_frame']\n",
    "\n",
    "    # what are these 15 time frames' index?\n",
    "    processed_time_frame_index_list = row.iloc[0]['processed_time_frame_index_list']\n",
    "\n",
    "    result.append([patient_id, patient_group, batch_index,image_full_slice_file, seg_full_slice_file,  image_nonzero_slice_file, seg_nonzero_slice_file, image_nonzero_slice_file_loose, seg_nonzero_slice_file_loose,\n",
    "                   start_slice_name, total_slice_num, nonzero_slice_num, nonzero_slice_start_index, nonzero_slice_end_index, nonzero_slice_num_loose, nonzero_slice_start_index_loose, nonzero_slice_end_index_loose,\n",
    "                   original_time_frame_num, ED, ES, processed_time_frame_num, ED_index_in_processed_time_frame, ES_index_in_processed_time_frame, processed_time_frame_index_list])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(result, columns=['patient_id', 'patient_group', 'batch_index', 'image_full_slice_file', 'seg_full_slice_file', 'image_nonzero_slice_file', 'seg_nonzero_slice_file', 'image_nonzero_slice_file_loose', 'seg_nonzero_slice_file_loose',\n",
    "                                    'start_slice_name', 'total_slice_num', 'nonzero_slice_num', 'nonzero_slice_start_index', 'nonzero_slice_end_index', 'nonzero_slice_num_loose', 'nonzero_slice_start_index_loose', 'nonzero_slice_end_index_loose',\n",
    "                                    'original_time_frame_num', 'ED', 'ES', 'processed_time_frame_num', 'ED_index_in_processed_time_frame', 'ES_index_in_processed_time_frame', 'processed_time_frame_index_list'])\n",
    "\n",
    "df.to_excel(os.path.join(patient_list_path, 'ACDC_Patient_List_training_testing.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run following for STACOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/mnt/camca_NAS/SAM_for_CMR/data/STACOM_database/temporal'\n",
    "patient_list_path = '/mnt/camca_NAS/SAM_for_CMR/data/Patient_list/'\n",
    "basic_info_file = pd.read_excel(os.path.join(patient_list_path, 'STACOM_basic_info.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "all_dataset = ff.find_all_target_files(['*'],os.path.join(data_path))\n",
    "print(len(all_dataset))\n",
    "######### in total there should be 100 training cases\n",
    "\n",
    "# divide dataset into 5 batches, batch 0 to batch 4\n",
    "\n",
    "if len(all_dataset)%5 == 0:\n",
    "    batch_size = len(all_dataset)//5\n",
    "else:\n",
    "    batch_size = len(all_dataset)//5 + 1\n",
    "\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in range(len(all_dataset)):\n",
    "    \n",
    "    folder = all_dataset[i]\n",
    "    patient_id = os.path.basename(folder)\n",
    "    patient_group = 'training'\n",
    "\n",
    "    # find the corresponding row in basic info spreadsheet\n",
    "    row = basic_info_file[basic_info_file['patient_id'] == patient_id]\n",
    "    \n",
    "    if patient_group[0:3] == 'tra': # training\n",
    "        batch_index = i // batch_size\n",
    "    else:\n",
    "        \n",
    "      batch_index = 5\n",
    "    \n",
    "    # image file with all slices (including non-zero slices and zero slices)\n",
    "    image_full_slice_file = os.path.join(folder, '4d_temporal_img_full.nii.gz')\n",
    "\n",
    "    # segmentation file with all slices (including non-zero slices and zero slices)\n",
    "    seg_full_slice_file = os.path.join(folder, '4d_temporal_seg_full.nii.gz')\n",
    "\n",
    "    # image file with only nonzero slices - strict: both ED and ES need to have gt segmentation\n",
    "    image_nonzero_slice_file = os.path.join(folder, '4d_temporal_img_nonzero.nii.gz')\n",
    "\n",
    "    # segmentation file with only nonzero slices - strict: both ED and ES need to have gt segmentation\n",
    "    seg_nonzero_slice_file = os.path.join(folder, '4d_temporal_seg_nonzero.nii.gz')\n",
    "\n",
    "    # image file with only nonzero slices - loose: either ED or ES has gt segmentation\n",
    "    image_nonzero_slice_file_loose = os.path.join(folder, '4d_temporal_img_nonzero_loose.nii.gz')\n",
    "\n",
    "    # segmentation file with only nonzero slices - loose: either ED or ES has gt segmentation\n",
    "    seg_nonzero_slice_file_loose = os.path.join(folder, '4d_temporal_seg_nonzero_loose.nii.gz')\n",
    "\n",
    "    # image start from 'base' or 'apex'\n",
    "    start_slice_name = row.iloc[0]['start_slice_name']\n",
    "\n",
    "    # image total slice number\n",
    "    total_slice_num = row.iloc[0]['total_slice_num']\n",
    "\n",
    "    # image nonzero slice number\n",
    "    nonzero_slice_num = row.iloc[0]['nonzero_slice_num']\n",
    "\n",
    "    # image nonzero slice start index\n",
    "    nonzero_slice_start_index = row.iloc[0]['nonzero_slice_start_index']\n",
    "\n",
    "    # image nonzero slice end index\n",
    "    nonzero_slice_end_index = row.iloc[0]['nonzero_slice_end_index']\n",
    "\n",
    "    # image nonzero slice number - loose\n",
    "    nonzero_slice_num_loose = row.iloc[0]['nonzero_slice_num_loose']\n",
    "\n",
    "    # image nonzero slice start index - loose\n",
    "    nonzero_slice_start_index_loose = row.iloc[0]['nonzero_slice_start_index_loose']\n",
    "\n",
    "    # image nonzero slice end index - loose\n",
    "    nonzero_slice_end_index_loose = row.iloc[0]['nonzero_slice_end_index_loose']\n",
    "\n",
    "    # original time frame number\n",
    "    original_time_frame_num = row.iloc[0]['tf_num']\n",
    "\n",
    "    # ED time frame\n",
    "    ED = row.iloc[0]['ED']\n",
    "\n",
    "    # ES time frame\n",
    "    ES = row.iloc[0]['ES']\n",
    " \n",
    "    # processed time frame number: always 15, ALWAYS including ED and ES\n",
    "    processed_time_frame_num = row.iloc[0]['processed_time_frame_num']\n",
    "\n",
    "    # ED index in the processed time frame\n",
    "    ED_index_in_processed_time_frame = row.iloc[0]['ED_index_in_processed_time_frame']\n",
    "\n",
    "    # ES index in the processed time frame\n",
    "    ES_index_in_processed_time_frame = row.iloc[0]['ES_index_in_processed_time_frame']\n",
    "\n",
    "    # what are these 15 time frames' index?\n",
    "    processed_time_frame_index_list = row.iloc[0]['processed_time_frame_index_list']\n",
    "\n",
    "    result.append([patient_id, patient_group, batch_index,image_full_slice_file, seg_full_slice_file,  image_nonzero_slice_file, seg_nonzero_slice_file, image_nonzero_slice_file_loose, seg_nonzero_slice_file_loose,\n",
    "                   start_slice_name, total_slice_num, nonzero_slice_num, nonzero_slice_start_index, nonzero_slice_end_index,  nonzero_slice_num_loose, nonzero_slice_start_index_loose, nonzero_slice_end_index_loose,\n",
    "                   original_time_frame_num, ED, ES, processed_time_frame_num, ED_index_in_processed_time_frame, ES_index_in_processed_time_frame, processed_time_frame_index_list])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(result, columns=['patient_id', 'patient_group', 'batch_index', 'image_full_slice_file', 'seg_full_slice_file', 'image_nonzero_slice_file', 'seg_nonzero_slice_file', 'image_nonzero_slice_file_loose', 'seg_nonzero_slice_file_loose',\n",
    "                                    'start_slice_name', 'total_slice_num', 'nonzero_slice_num', 'nonzero_slice_start_index', 'nonzero_slice_end_index', 'nonzero_slice_num_loose', 'nonzero_slice_start_index_loose', 'nonzero_slice_end_index_loose',\n",
    "                                    'original_time_frame_num', 'ED', 'ES', 'processed_time_frame_num', 'ED_index_in_processed_time_frame', 'ES_index_in_processed_time_frame', 'processed_time_frame_index_list'])\n",
    "\n",
    "df.to_excel(os.path.join(patient_list_path, 'STACOM_Patient_List_training_testing.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
